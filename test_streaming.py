#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Azure OpenAI Proxy Streaming Test Script
æµ‹è¯• Azure OpenAI Proxy çš„ streaming æ¨¡å¼åŠŸèƒ½
"""

import os
import json
import requests
import time
from typing import Generator

def test_streaming_chat():
    """æµ‹è¯• streaming èŠå¤©åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹æµ‹è¯• Azure OpenAI Proxy Streaming æ¨¡å¼...")

    # API ç«¯ç‚¹
    base_url = "http://localhost:8000"
    endpoint = f"{base_url}/v1/chat/completions"

    # æµ‹è¯•è¯·æ±‚æ•°æ®
    request_data = {
        "model": "gpt-4o-mini",
        "messages": [
            {
                "role": "user",
                "content": "è¯·ç”¨ä¸­æ–‡å›ç­”ï¼šè§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿè¯·ç”¨æµå¼å“åº”ï¼Œæ¯ç”Ÿæˆä¸€ä¸ªè¯å°±è¿”å›ä¸€æ¬¡ã€‚"
            }
        ],
        "stream": True,
        "max_tokens": 200,
        "temperature": 0.7
    }

    print(f"ğŸ“¡ å‘é€è¯·æ±‚åˆ°: {endpoint}")
    print(f"ğŸ“ è¯·æ±‚å†…å®¹: {request_data['messages'][0]['content']}")

    try:
        # å‘é€ POST è¯·æ±‚
        response = requests.post(
            endpoint,
            json=request_data,
            headers={"Content-Type": "application/json"},
            stream=True
        )

        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return

        print("âœ… è¿æ¥æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æµå¼å“åº”...")
        print("-" * 50)

        # å¤„ç†æµå¼å“åº”
        chunk_count = 0
        full_content = ""

        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    chunk_count += 1
                    data_str = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€

                    if data_str == '[DONE]':
                        print("\n" + "-" * 50)
                        print("âœ… æµå¼å“åº”å®Œæˆ")
                        break

                    try:
                        chunk_data = json.loads(data_str)
                        if 'choices' in chunk_data and chunk_data['choices']:
                            choice = chunk_data['choices'][0]
                            if 'delta' in choice and 'content' in choice['delta']:
                                content = choice['delta']['content']
                                if content:
                                    full_content += content
                                    print(content, end='', flush=True)

                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  JSON è§£æé”™è¯¯: {e}")

        print(f"\n\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»å—æ•°: {chunk_count}")
        print(f"   æ€»å­—ç¬¦æ•°: {len(full_content)}")
        print(f"   å®Œæ•´å†…å®¹: {full_content}")

    except requests.exceptions.ConnectionError:
        print("âŒ è¿æ¥å¤±è´¥ï¼Œè¯·ç¡®ä¿ Azure OpenAI Proxy æœåŠ¡æ­£åœ¨è¿è¡Œ")
        print("ğŸ’¡ å¯åŠ¨æœåŠ¡: python app.py")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

def test_health_check():
    """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    print("\nğŸ” æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹...")
    try:
        response = requests.get("http://localhost:8000/health")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… å¥åº·æ£€æŸ¥é€šè¿‡: {data}")
        else:
            print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: HTTP {response.status_code}")
    except Exception as e:
        print(f"âŒ å¥åº·æ£€æŸ¥é”™è¯¯: {e}")

def test_models_list():
    """æµ‹è¯•æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹...")
    try:
        response = requests.get("http://localhost:8000/v1/models")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… æ¨¡å‹åˆ—è¡¨: {json.dumps(data, indent=2, ensure_ascii=False)}")
        else:
            print(f"âŒ æ¨¡å‹åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ—è¡¨é”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Azure OpenAI Proxy Streaming æµ‹è¯•å·¥å…·")
    print("=" * 50)

    # å…ˆæµ‹è¯•åŸºæœ¬ç«¯ç‚¹
    test_health_check()
    test_models_list()

    # æµ‹è¯• streaming åŠŸèƒ½
    test_streaming_chat()

    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()